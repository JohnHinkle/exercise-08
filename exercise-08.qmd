---
title: "exercise-08"
author: "John Hinkle"
format: html
self-contained: true
editor: visual
---

## Step 1a: Load data

```{r}
library(tidyverse)
d <- read_csv("https://raw.githubusercontent.com/difiore/ada-datasets/main/Street_et_al_2017.csv")
```

## Step 1b: Generate summary statistics

```{r}
library(skimr)
skim(d) # generate summary statistics
```

## Step 2: Plot brain size as a function of other variables

```{r}
library(ggplot2)
p1 <- ggplot(d, aes(x=Group_size, y=ECV)) +
  geom_point()
p2 <- ggplot(d, aes(x=Longevity, y=ECV)) +
  geom_point()
p3 <- ggplot(d, aes(x=Weaning, y=ECV)) +
  geom_point()
p4 <- ggplot(d, aes(x=Repro_lifespan, y=ECV)) +
  geom_point()

library(patchwork)
(p1 | p2)/ (p3 | p4) + plot_annotation(tag_levels = "I")
```

## Step 3: Manually derive regression coefficients for brain size as a function of social group size

```{r}
group_size <- d$Group_size
brain_size <- d$ECV

complete_data <- complete.cases(group_size, brain_size)

x <- group_size[complete_data]
y <- brain_size[complete_data]

# Calculate covariance manually
x_dev <- x - mean(x)
y_dev <- y - mean(y)
covariance <- sum(x_dev*y_dev) / (length(x)-1)

# Calculate variance manually 
variance <- sum((x-mean(x))^2) / (length(x)-1)

(beta1 <- covariance / variance) # slope
(beta0 <- mean(y) - beta1 * mean(x)) # y-intercept
```

## Step 4: Use 'lm()' to get regression coefficients

The beta coefficents using the 'lm()' function as the same as those manually calculated in Step 3.

```{r}
m <- lm(ECV~Group_size, data=d)
m$coefficients
```

## Step 5: Calculate the regression coefficients for the three major primate radiations

By looking at them, the regression coefficients are different between the three groups.

```{r}
catarrhini <- filter(d, Taxonomic_group == "Catarrhini")
platyrrhini <- filter(d, Taxonomic_group == "Platyrrhini")
strepsirhini <- filter(d, Taxonomic_group == "Strepsirhini")

m_catarrhini <- lm(ECV~Group_size, data=catarrhini)
m_catarrhini$coefficients
m_platyrrhini <- lm(ECV~Group_size, data=platyrrhini)
m_platyrrhini$coefficients
m_strepsirhini <- lm(ECV~Group_size, data=strepsirhini)
m_strepsirhini$coefficients
```

## Step 6a: Calculate standard error, p-value, and 95% confidence interval for the slope coefficient

```{r}
# Standard error of slope coefficent
MSE <- sum(m$residuals^2) / (length(x) - 2)
SSX <- sum((x-mean(x))^2)
manual_std_error <- sqrt(MSE / SSX)

# 95% confidence interval
slope <- as.numeric(m$coefficients[2])
t_value <- qt(0.975, df = length(x) - 2)
CI_lower <- slope  - t_value * manual_std_error
CI_upper <- slope  + t_value * manual_std_error

# p value
t_statistic <- slope / manual_std_error
manual_p_value <- 2 * (1 - pt(abs(t_statistic), df = length(x) - 2))

paste("The standard error is:", manual_std_error)
paste("The 95% CI is:", paste(CI_lower, CI_upper))
paste("p =", manual_p_value)
```

## Step 6b: Calculate standard error, p-value, and 95% confidence interval for the slope coefficient

```{r}
library(broom)

# Getting model results into a table
tidy_m <- broom::tidy(m)

# Pulling standard error
std_error <- tidy_m |>
  filter(term == "Group_size") |>
  pull(std.error)

# Pulling 95% confidence interval
CI <- confint(m, level = 0.95)[2,]

# Pulling p-value
p_value <- tidy_m |>
  filter(term == "Group_size") |>
  pull(p.value)

paste("The standard error is:", std_error)
paste("The 95% CI is:", paste(CI, collapse = ", "))
paste("p =", p_value)
```

## Step 7: Permutation approach to generate a null sampling distribution for the slope coefficient

**What is it that we are permuting?** The slope coefficient, so that we can get a permutation distribution of the slope coefficient were we have broken the relationship between brain size and group size.

**What is the p value associated with the original slope coefficient?** p = 7.25943489958251e-11

```{r}
library(mosaic)
n_perm <- 1000

# Original or "observed" slope coefficent
obs_slope <- tidy_m |>
  filter(term == "weight") |>
  pull(estimate)

perm <- do(n_perm) * {
  d_new <- d
  d_new$Group_size<- sample(d_new$Group_size)
  m <- lm(data = d_new, ECV~Group_size)
  broom::tidy(m) |>
    filter(term == "Group_size") |>
    pull(estimate)
}

# Calculate p-value
perm_p_value <- sum(perm$result > abs(obs_slope) | perm$result < -1 * abs(obs_slope))/n_perm
paste("p = ", perm_p_value)
```

## Step 8: Use bootstrapping to generate a 95% CI for the estimate of the slope coefficient using both the quantile method and the theory-based method

```{r}
library(infer)

# Bootstrapping
boot.slope <- specify(d, ECV~Group_size) |>
  generate(reps = 1000, type = "bootstrap") |>
  calculate(stat = "slope")

boot_vector <- boot.slope$stat

# Theoretical CI function
CI <- function(x, level = 0.95) {
    alpha <- 1 - level
    ci <- mean(x) + c(-1, 1) * qnorm(1 - (alpha/2)) * sqrt(var(x)/length(x))
    print(ci)
}
```

Both confidence intervals suggest that the slope is different from zero as neither confidence interval includes 0.

```{r}
# Quantile Method 95% CI
quantile(probs = c(0.025, 0.975), boot_vector)

# Theoretical Method 95% CI
CI(boot_vector) 
```
