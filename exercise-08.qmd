---
title: "exercise-08"
author: "John Hinkle"
format: html
self-contained: true
editor: visual
---

## Step 1a: Load data

```{r}
library(tidyverse)
d <- read_csv("https://raw.githubusercontent.com/difiore/ada-datasets/main/Street_et_al_2017.csv")
```

## Step 1b: Generate summary statistics

```{r}
library(skimr)
skim(d) # generate summary statistics
```

## Step 2: Plot brain size as a function of other variables

```{r}
library(ggplot2)
p1 <- ggplot(d, aes(x=Group_size, y=ECV)) +
  geom_point()
p2 <- ggplot(d, aes(x=Longevity, y=ECV)) +
  geom_point()
p3 <- ggplot(d, aes(x=Weaning, y=ECV)) +
  geom_point()
p4 <- ggplot(d, aes(x=Repro_lifespan, y=ECV)) +
  geom_point()

library(patchwork)
(p1 | p2)/ (p3 | p4) + plot_annotation(tag_levels = "I")
```

## Step 3: Manually derive beta coefficents for brain size as a function of social group size

```{r}
x <- d$Group_size
y <- d$ECV

complete_data <- complete.cases(x,y)

x <- x[complete_data]
y <- y[complete_data]

(beta1 <- cov(x, y) / var(x)) # slope
(beta0 <- mean(y) - beta1 * mean(x)) # y-intercept
```

## Step 4: Use 'lm()' to get beta coefficents

The beta coefficents using the 'lm()' function as the same as those manually calculated in Step 3.

```{r}
m <- lm(ECV~Group_size, data=d)
summary(m)
```

## Step 5:

```{r}
catarrhini <- filter(d, Taxonomic_group == "Catarrhini")
platyrrhini <- filter(d, Taxonomic_group == "Platyrrhini")
strepsirhini <- filter(d, Taxonomic_group == "Strepsirhini")

m_catarrhini <- lm(ECV~Group_size, data=catarrhini)
summary(m_catarrhini)
m_platyrrhini <- lm(ECV~Group_size, data=platyrrhini)
summary(m_platyrrhini)
m_strepsirhini <- lm(ECV~Group_size, data=strepsirhini)
summary(m_strepsirhini)
```

## Step 6:

```{r}
library(broom)
tidy_m <- broom::tidy(m)

(std_error <- tidy_m |>
  filter(term == "Group_size") |>
  pull(std.error))

(p_value <- tidy_m |>
  filter(term == "Group_size") |>
  pull(p.value))

(CI <- confint(m, level = 0.95)[2,]) # 95% CI
```

## Step 7a

```{r}
library(infer)

alpha <- 0.05
confidence_level <- 1 - alpha
p_lower <- alpha/2
p_upper <- 1 - (alpha/2)
degrees_of_freedom <- nrow(d) - 2
critical_value <- qt(p_upper, df = degrees_of_freedom)

obs_slope <- tidy_m |>
  filter(term == "Group_size") |>
  pull(estimate)

nperm <- 1000
perm <- d |>
  # specify model
  specify(ECV~Group_size) |>
  # use a null hypothesis of independence
  hypothesize(null = "independence") |>
  # generate permutation replicates
  generate(reps = nperm, type = "permute") |>
  # calculate the slope statistic
  calculate(stat = "slope")
# calculate se as sd of permutation distribution
perm.se <- sd(perm$stat)
# visualize
visualize(perm) + shade_p_value(obs_stat = obs_slope, direction = "two_sided")
```

## Step 7b

```{r}

```

## Step 8

```{r}

library(infer)

boot.slope <- d |>
  specify(ECV~Group_size) |>
  generate(reps = 1000, type = "bootstrap") |>
  calculate(stat = "slope")

quantile(probs = c(0.025, 0.975), boot.slope$stat)

CI <- function(x, level = 0.95) {
    alpha <- 1 - level
    ci <- mean(x) + c(-1, 1) * qnorm(1 - (alpha/2)) * sqrt(var(x)/length(x))
    return(ci)
}

print(CI(boot.slope$stat))
```
